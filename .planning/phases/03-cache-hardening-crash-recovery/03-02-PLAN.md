---
phase: 03-cache-hardening-crash-recovery
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - src/research/checkpoints.py
  - src/research/suburb_discovery.py
  - src/app.py
autonomous: true

must_haves:
  truths:
    - "Running with --resume after a crash skips already-completed suburbs and continues from the last checkpoint"
    - "Pipeline state is checkpointed after discovery phase completion"
    - "Pipeline state is checkpointed after each batch of 5 suburbs during research (calling parallel_research_suburbs with slices of 5 candidates)"
    - "If the latest checkpoint is corrupted, the system falls back to the previous checkpoint automatically"
    - "Last 3 checkpoints are retained for rollback"
    - "Checkpoint files use atomic writes (via atomic_write_json from cache.py) with SHA-256 checksums"
  artifacts:
    - path: "src/research/checkpoints.py"
      provides: "CheckpointManager class with save/load/rollback"
      contains: "class CheckpointManager"
    - path: "src/research/suburb_discovery.py"
      provides: "SuburbCandidate.to_dict() for checkpoint serialization"
      contains: "def to_dict"
    - path: "src/app.py"
      provides: "--resume flag and checkpoint-aware pipeline"
      contains: "--resume"
  key_links:
    - from: "src/research/checkpoints.py"
      to: "src/research/cache.py"
      via: "atomic_write_json import (created by Plan 03-01, Wave 1)"
      pattern: "from research.cache import atomic_write_json"
    - from: "src/app.py"
      to: "src/research/checkpoints.py"
      via: "CheckpointManager usage"
      pattern: "from research.checkpoints import CheckpointManager"
    - from: "src/app.py"
      to: "argparse --resume flag"
      via: "argument parsing"
      pattern: "add_argument.*--resume"
---

<objective>
Create a checkpoint system that saves pipeline state at key milestones (after discovery, every 5 suburbs during research) and enables resuming interrupted runs via --resume flag.

Purpose: Long research runs (10+ suburbs, each taking minutes) should not lose all progress on crash or interruption. Users can resume from the last valid checkpoint, skipping already-completed work.

Output: New checkpoints.py module with CheckpointManager. SuburbCandidate.to_dict() for serialization. Modified app.py with --resume flag and checkpoint integration in run_research_pipeline().
</objective>

<execution_context>
@.planning/phases/03-cache-hardening-crash-recovery/03-RESEARCH.md
@.planning/phases/03-cache-hardening-crash-recovery/03-01-SUMMARY.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@src/app.py
@src/research/suburb_discovery.py
@src/research/suburb_research.py
@src/research/cache.py
@src/models/suburb_metrics.py
@src/config/settings.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create CheckpointManager module and add SuburbCandidate.to_dict()</name>
  <files>src/research/checkpoints.py, src/research/suburb_discovery.py</files>
  <action>
**Part A: Add to_dict() to SuburbCandidate in src/research/suburb_discovery.py**

SuburbCandidate is a plain class (not Pydantic). Add a to_dict() method that returns its attributes as a dict suitable for JSON serialization and reconstruction via SuburbCandidate(data):

```python
def to_dict(self) -> dict:
    return {
        "name": self.name, "state": self.state, "lga": self.lga,
        "region": self.region, "median_price": self.median_price,
        "growth_signals": self.growth_signals,
        "major_events_relevance": self.major_events_relevance,
        "data_quality": self.data_quality
    }
```

**Part B: Create src/research/checkpoints.py with CheckpointManager class**

```python
"""
Checkpoint manager for pipeline crash recovery.

Saves pipeline state after discovery and periodically during research,
enabling interrupted runs to resume from the last valid checkpoint.
"""
```

Import `atomic_write_json` from `src.research.cache` (created by Plan 03-01). This is a cross-plan dependency -- Plan 03-01 must execute first (enforced by wave structure: 03-01 is Wave 1, 03-02 is Wave 2).

Also import: hashlib, json, time, logging, Path from pathlib, Optional from typing.

**CheckpointManager class:**

Constructor `__init__(self, run_id: str, checkpoint_dir: Path, max_checkpoints: int = 3)`:
- Store run_id, create checkpoint_dir / run_id subdirectory (mkdir parents=True, exist_ok=True)
- Store max_checkpoints for retention limit

**save_checkpoint(self, phase: str, state: dict, sequence: int = 0)**:
- phase is "discovery" or "research"
- If sequence > 0, checkpoint_name = f"{phase}_{sequence:04d}", else checkpoint_name = phase
- Build checkpoint_data dict: {"run_id": self.run_id, "phase": phase, "sequence": sequence, "timestamp": time.time(), "state": state}
- Serialize to JSON string with json.dumps(checkpoint_data, indent=2)
- Calculate SHA-256 checksum of the JSON string (utf-8 encoded)
- Use atomic_write_json() to write checkpoint file (pass checkpoint_data dict, not the string -- atomic_write_json handles serialization)
- Write checksum to {checkpoint_name}.json.sha256 using atomic_write_json() as well (wrap the checksum string in a dict: {"checksum": checksum}) -- this ensures consistency with the atomic write pattern. Alternatively, since the checksum file is tiny and non-critical for recovery (the checkpoint file itself is the important one), plain write_text() is acceptable. Choose atomic_write_json for consistency.
  NOTE: atomic_write_json() accepts a dict and writes JSON. For the checksum file, use plain `checksum_path.write_text(checksum)` since atomic_write_json expects a dict. The checksum file is a validation aid, not critical data -- if it's corrupted, the checkpoint simply fails validation and we roll back to the previous one.
- Call _cleanup_old_checkpoints(phase)
- Log: f"Checkpoint saved: {checkpoint_name}"

**load_latest_checkpoint(self, phase: str) -> Optional[dict]**:
- Get all checkpoint candidates for this phase using _get_checkpoint_candidates(phase)
- For each candidate (sorted latest-first):
  - Read checkpoint file and checksum file
  - Verify SHA-256 checksum matches
  - If mismatch, log warning and try next candidate (rollback)
  - If valid, parse JSON and verify run_id matches self.run_id
  - Return state dict from checkpoint_data["state"]
- If no valid checkpoint found, return None and log warning

**_get_checkpoint_candidates(self, phase: str) -> list[Path]**:
- If phase == "discovery": return [checkpoint_dir/run_id/discovery.json] if exists
- If phase == "research": glob for "research_*.json" in checkpoint_dir/run_id/, sort by name descending (latest first), then append discovery.json as final fallback
- Filter to only existing files

**_cleanup_old_checkpoints(self, phase: str)**:
- Only applies to "research" phase (don't clean discovery)
- Glob for "research_*.json", sort by mtime descending
- Delete checkpoints beyond max_checkpoints (delete both .json and .json.sha256)
- Log each deletion

**has_checkpoint(self, phase: str) -> bool**:
- Return True if any valid checkpoint file exists for the phase
  </action>
  <verify>
Run: `cd /Users/robertli/Desktop/local-projects/agentic-re-researcher && python -c "
from src.research.checkpoints import CheckpointManager
from src.research.suburb_discovery import SuburbCandidate
from pathlib import Path
import tempfile, json

# Test SuburbCandidate.to_dict()
c = SuburbCandidate({'name': 'Test', 'state': 'QLD', 'lga': 'Brisbane', 'region': 'SEQ'})
d = c.to_dict()
assert d['name'] == 'Test' and d['state'] == 'QLD'
c2 = SuburbCandidate(d)
assert c2.name == 'Test' and c2.state == 'QLD'
print('SuburbCandidate.to_dict() roundtrip OK')

with tempfile.TemporaryDirectory() as td:
    mgr = CheckpointManager('test-run', Path(td))

    # Save discovery checkpoint
    mgr.save_checkpoint('discovery', {'candidates': [{'name': 'TestSuburb', 'state': 'QLD'}]})
    assert mgr.has_checkpoint('discovery')

    # Load it back
    state = mgr.load_latest_checkpoint('discovery')
    assert state['candidates'][0]['name'] == 'TestSuburb'

    # Save research checkpoints
    for i in range(1, 8):
        mgr.save_checkpoint('research', {'completed': list(range(i))}, sequence=i*5)

    # Only last 3 should remain
    research_files = list(Path(td).glob('test-run/research_*.json'))
    assert len(research_files) == 3, f'Expected 3, got {len(research_files)}'

    # Load latest research
    state = mgr.load_latest_checkpoint('research')
    assert len(state['completed']) == 7

    # Test checksum validation (corrupt a file)
    latest = sorted(Path(td).glob('test-run/research_*.json'))[-1]
    latest.write_text('{\"corrupted\": true}')
    # Should fall back to previous checkpoint
    state = mgr.load_latest_checkpoint('research')
    assert state is not None
    print('ALL CHECKPOINT TESTS PASSED')
"`
  </verify>
  <done>CheckpointManager class exists with save_checkpoint(), load_latest_checkpoint(), has_checkpoint(), _get_checkpoint_candidates(), and _cleanup_old_checkpoints(). Checkpoints use atomic writes (via atomic_write_json from cache.py) with SHA-256 validation. Last 3 research checkpoints retained. Rollback to previous checkpoint on corruption. SuburbCandidate has to_dict() that roundtrips through SuburbCandidate(data).</done>
</task>

<task type="auto">
  <name>Task 2: Integrate checkpoints into pipeline with --resume flag and batched research</name>
  <files>src/app.py</files>
  <action>
Modify src/app.py to support checkpoint-based resume. This task ONLY modifies app.py. SuburbMetrics is a Pydantic BaseModel -- use `.model_dump()` for serialization and `SuburbMetrics.model_validate(d)` for deserialization (NOT to_dict/from_dict which don't exist on Pydantic models).

1. **Add --resume argument** to the argparse section (after --compare):
   ```python
   parser.add_argument(
       "--resume",
       type=str,
       metavar="RUN_ID",
       default=None,
       help="Resume an interrupted run from its last checkpoint (provide the run_id)"
   )
   ```

2. **Update run_research_pipeline() signature** to accept optional resume_from parameter:
   ```python
   def run_research_pipeline(
       user_input: UserInput,
       progress_callback: Optional[Callable[[str], None]] = None,
       resume_from: Optional[str] = None
   ) -> RunResult:
   ```

3. **Add checkpoint logic inside run_research_pipeline()** at the start of the try block (after creating run_result):
   ```python
   from research.checkpoints import CheckpointManager
   from models.suburb_metrics import SuburbMetrics

   checkpoint_mgr = CheckpointManager(user_input.run_id, settings.CHECKPOINT_DIR)
   candidates = None
   completed_suburbs = set()
   metrics_list = []

   # Resume from checkpoint if requested
   if resume_from:
       _progress(f"Attempting to resume run: {resume_from}")

       # Try loading discovery checkpoint
       discovery_state = checkpoint_mgr.load_latest_checkpoint("discovery")
       if discovery_state:
           from research.suburb_discovery import SuburbCandidate
           candidates = [SuburbCandidate(d) for d in discovery_state["candidates"]]
           _progress(f"Resumed discovery: {len(candidates)} candidates from checkpoint")

       # Try loading research checkpoint
       research_state = checkpoint_mgr.load_latest_checkpoint("research")
       if research_state:
           completed_suburbs = set(research_state.get("completed_suburbs", []))
           # SuburbMetrics is Pydantic v2: use model_validate() to reconstruct from dict
           metrics_list = [SuburbMetrics.model_validate(d) for d in research_state.get("metrics_list", [])]
           _progress(f"Resumed research: {len(completed_suburbs)} suburbs already completed")
   ```

4. **Modify Step 1 (Discovery)** to checkpoint after completion and skip if resumed:
   - Wrap discovery in `if candidates is None:` check
   - After `parallel_discover_suburbs()` succeeds, save discovery checkpoint:
     ```python
     # SuburbCandidate is a plain class with to_dict() added in Task 1
     checkpoint_mgr.save_checkpoint("discovery", {
         "candidates": [c.to_dict() for c in candidates]
     })
     ```

5. **Modify Step 2 (Research)** to use batched processing with checkpoints every 5 suburbs:
   - Before the research call, filter out completed suburbs:
     ```python
     if completed_suburbs:
         original_count = len(candidates)
         candidates = [c for c in candidates if f"{c.name}_{c.state}" not in completed_suburbs]
         _progress(f"Skipping {original_count - len(candidates)} already-completed suburbs")
     ```
   - Replace the single parallel_research_suburbs() call with batched processing. The existing parallel_research_suburbs() function takes a list of candidates and processes them all with a ThreadPoolExecutor. We call it multiple times with slices of 5 candidates each:
     ```python
     research_candidates = candidates[:research_count]
     batch_size = 5
     for batch_start in range(0, len(research_candidates), batch_size):
         batch = research_candidates[batch_start:batch_start + batch_size]
         _progress(f"Researching batch {batch_start // batch_size + 1}: suburbs {batch_start + 1}-{batch_start + len(batch)} of {len(research_candidates)}")
         batch_metrics = parallel_research_suburbs(
             batch, user_input.dwelling_type, user_input.max_median_price,
             max_suburbs=len(batch), provider=user_input.provider,
             progress_callback=progress_callback
         )
         for m in batch_metrics:
             completed_suburbs.add(f"{m.identification.name}_{m.identification.state}")
             metrics_list.append(m)

         # Checkpoint after each batch
         # SuburbMetrics is Pydantic v2: use .model_dump() for serialization
         checkpoint_mgr.save_checkpoint("research", {
             "completed_suburbs": list(completed_suburbs),
             "metrics_list": [m.model_dump() for m in metrics_list]
         }, sequence=len(completed_suburbs))
         _progress(f"Checkpoint saved: {len(completed_suburbs)} suburbs completed")
     ```

6. **Replace the old metrics_list references** downstream:
   - After the batched loop, the `metrics_list` variable is already populated
   - The existing `if not metrics_list:` check and ranking steps work unchanged
   - No changes needed to Steps 3 (Ranking) or 4 (Report generation)

7. **Handle --resume in main()** after argument parsing, before `# Validate num_suburbs`:
   ```python
   # Handle --resume
   if args.resume:
       user_input = UserInput(
           max_median_price=args.max_price,
           dwelling_type=args.dwelling_type,
           regions=args.regions,
           num_suburbs=args.num_suburbs,
           provider=args.provider,
           run_id=args.resume,  # Use the provided run_id
           interface_mode="cli"
       )
       run_result = run_research_pipeline(user_input, resume_from=args.resume)
       if run_result.status == "completed":
           sys.exit(0)
       else:
           sys.exit(1)
   ```

Important: The web server in src/ui/web/server.py calls run_research_pipeline() -- the new resume_from parameter has a default of None so it won't break existing calls.
  </action>
  <verify>
Run these checks:
1. `cd /Users/robertli/Desktop/local-projects/agentic-re-researcher && python -c "from src.app import run_research_pipeline; import inspect; sig = inspect.signature(run_research_pipeline); assert 'resume_from' in sig.parameters; print('resume_from param OK')"`
2. `python -c "from src.app import main; print('main import OK')"`
3. `python -m src.app --help` should show --resume in the output
4. `python -c "
from src.models.suburb_metrics import SuburbMetrics, SuburbIdentification, MarketMetricsCurrent
# Verify Pydantic roundtrip works as planned
m = SuburbMetrics(
    identification=SuburbIdentification(name='Test', state='QLD', lga='Brisbane'),
    market_current=MarketMetricsCurrent(median_price=500000)
)
d = m.model_dump()
m2 = SuburbMetrics.model_validate(d)
assert m2.identification.name == 'Test'
print('SuburbMetrics model_dump/model_validate roundtrip OK')
"`
5. `python -c "from src.research.suburb_discovery import SuburbCandidate; c = SuburbCandidate({'name': 'Test', 'state': 'QLD'}); d = c.to_dict(); assert d['name'] == 'Test'; c2 = SuburbCandidate(d); assert c2.name == 'Test'; print('SuburbCandidate to_dict roundtrip OK')"`
  </verify>
  <done>
--resume flag exists in CLI argument parser. run_research_pipeline() accepts resume_from parameter. Discovery checkpoint saved after parallel_discover_suburbs() using SuburbCandidate.to_dict(). Research is batched into groups of 5 suburbs, with a checkpoint saved after each batch using SuburbMetrics.model_dump() for serialization and SuburbMetrics.model_validate() for deserialization. Resume loads latest valid checkpoint, skips completed suburbs, continues from last batch. Web server calls are not broken (resume_from defaults to None).
  </done>
</task>

</tasks>

<verification>
1. CheckpointManager saves/loads checkpoints with SHA-256 validation
2. Corrupted checkpoint falls back to previous valid checkpoint
3. Only last 3 research checkpoints retained
4. --resume flag loads checkpoints and skips completed suburbs
5. Discovery checkpoint saved after discovery phase using SuburbCandidate.to_dict()
6. Research checkpoint saved every 5 suburbs using SuburbMetrics.model_dump()
7. Research resume deserializes with SuburbMetrics.model_validate() (Pydantic v2 API)
8. Atomic writes used for checkpoint files (via atomic_write_json from cache.py, created by Plan 03-01)
9. Web server pipeline call not broken by new parameter
10. parallel_research_suburbs() called with batches of 5 candidates (sliced from full list)
</verification>

<success_criteria>
- CheckpointManager class in src/research/checkpoints.py with save/load/rollback
- CheckpointManager imports atomic_write_json from src.research.cache (cross-plan dependency on 03-01)
- SuburbCandidate.to_dict() method exists and roundtrips through SuburbCandidate(data)
- --resume RUN_ID flag in CLI argument parser
- Discovery checkpoint created after parallel_discover_suburbs()
- Research processed in batches of 5, checkpoint after each batch
- SuburbMetrics serialized with .model_dump() and deserialized with .model_validate() (Pydantic v2)
- Resume skips already-completed suburbs
- Corrupted checkpoint triggers fallback to previous valid checkpoint
- Last 3 research checkpoints retained, older ones cleaned up
</success_criteria>

<output>
After completion, create `.planning/phases/03-cache-hardening-crash-recovery/03-02-SUMMARY.md`
</output>
