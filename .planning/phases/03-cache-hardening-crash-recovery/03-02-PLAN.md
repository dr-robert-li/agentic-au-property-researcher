---
phase: 03-cache-hardening-crash-recovery
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - src/research/checkpoints.py
  - src/app.py
  - src/research/suburb_discovery.py
  - src/research/suburb_research.py
autonomous: true

must_haves:
  truths:
    - "Running with --resume after a crash skips already-completed suburbs and continues from the last checkpoint"
    - "Pipeline state is checkpointed after discovery phase completion"
    - "Pipeline state is checkpointed periodically during suburb research (every 5 suburbs)"
    - "If the latest checkpoint is corrupted, the system falls back to the previous checkpoint automatically"
    - "Last 3 checkpoints are retained for rollback"
    - "Checkpoint files use atomic writes with SHA-256 checksums"
  artifacts:
    - path: "src/research/checkpoints.py"
      provides: "CheckpointManager class with save/load/rollback"
      contains: "class CheckpointManager"
    - path: "src/app.py"
      provides: "--resume flag and checkpoint-aware pipeline"
      contains: "--resume"
  key_links:
    - from: "src/research/checkpoints.py"
      to: "src/research/cache.py"
      via: "atomic_write_json import"
      pattern: "from research.cache import atomic_write_json"
    - from: "src/app.py"
      to: "src/research/checkpoints.py"
      via: "CheckpointManager usage"
      pattern: "from research.checkpoints import CheckpointManager"
    - from: "src/app.py"
      to: "argparse --resume flag"
      via: "argument parsing"
      pattern: "add_argument.*--resume"
---

<objective>
Create a checkpoint system that saves pipeline state at key milestones (after discovery, every N suburbs during research) and enables resuming interrupted runs via --resume flag.

Purpose: Long research runs (10+ suburbs, each taking minutes) should not lose all progress on crash or interruption. Users can resume from the last valid checkpoint, skipping already-completed work.

Output: New checkpoints.py module with CheckpointManager. Modified app.py with --resume flag and checkpoint integration in run_research_pipeline().
</objective>

<execution_context>
@.planning/phases/03-cache-hardening-crash-recovery/03-RESEARCH.md
@.planning/phases/03-cache-hardening-crash-recovery/03-01-SUMMARY.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@src/app.py
@src/research/suburb_discovery.py
@src/research/suburb_research.py
@src/research/cache.py
@src/config/settings.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create CheckpointManager module</name>
  <files>src/research/checkpoints.py</files>
  <action>
Create src/research/checkpoints.py with a CheckpointManager class:

```python
"""
Checkpoint manager for pipeline crash recovery.

Saves pipeline state after discovery and periodically during research,
enabling interrupted runs to resume from the last valid checkpoint.
"""
```

**CheckpointManager class:**

Constructor `__init__(self, run_id: str, checkpoint_dir: Path, max_checkpoints: int = 3)`:
- Store run_id, create checkpoint_dir / run_id subdirectory (mkdir parents=True, exist_ok=True)
- Store max_checkpoints for retention limit

**save_checkpoint(self, phase: str, state: dict, sequence: int = 0)**:
- phase is "discovery" or "research"
- If sequence > 0, checkpoint_name = f"{phase}_{sequence:04d}", else checkpoint_name = phase
- Build checkpoint_data dict: {"run_id": self.run_id, "phase": phase, "sequence": sequence, "timestamp": time.time(), "state": state}
- Serialize to JSON string with indent=2
- Calculate SHA-256 checksum of the JSON string (utf-8 encoded)
- Use atomic_write_json() from src/research/cache.py to write checkpoint file
- Write checksum to {checkpoint_name}.json.sha256 (plain text file)
- Call _cleanup_old_checkpoints(phase)
- Log: f"Checkpoint saved: {checkpoint_name}"

**load_latest_checkpoint(self, phase: str) -> Optional[dict]**:
- Get all checkpoint candidates for this phase using _get_checkpoint_candidates(phase)
- For each candidate (sorted latest-first):
  - Read checkpoint file and checksum file
  - Verify SHA-256 checksum matches
  - If mismatch, log warning and try next candidate (rollback)
  - If valid, parse JSON and verify run_id matches self.run_id
  - Return state dict from checkpoint_data["state"]
- If no valid checkpoint found, return None and log warning

**_get_checkpoint_candidates(self, phase: str) -> list[Path]**:
- If phase == "discovery": return [checkpoint_dir/run_id/discovery.json] if exists
- If phase == "research": glob for "research_*.json" in checkpoint_dir/run_id/, sort by name descending (latest first), then append discovery.json as final fallback
- Filter to only existing files

**_cleanup_old_checkpoints(self, phase: str)**:
- Only applies to "research" phase (don't clean discovery)
- Glob for "research_*.json", sort by mtime descending
- Delete checkpoints beyond max_checkpoints (delete both .json and .json.sha256)
- Log each deletion

**has_checkpoint(self, phase: str) -> bool**:
- Return True if any valid checkpoint exists for the phase

Import atomic_write_json from src.research.cache. Import hashlib, json, time, logging, Path from pathlib, Optional from typing.
  </action>
  <verify>
Run: `cd /Users/robertli/Desktop/local-projects/agentic-re-researcher && python -c "
from src.research.checkpoints import CheckpointManager
from pathlib import Path
import tempfile, json

with tempfile.TemporaryDirectory() as td:
    mgr = CheckpointManager('test-run', Path(td))

    # Save discovery checkpoint
    mgr.save_checkpoint('discovery', {'candidates': [{'name': 'TestSuburb', 'state': 'QLD'}]})
    assert mgr.has_checkpoint('discovery')

    # Load it back
    state = mgr.load_latest_checkpoint('discovery')
    assert state['candidates'][0]['name'] == 'TestSuburb'

    # Save research checkpoints
    for i in range(1, 8):
        mgr.save_checkpoint('research', {'completed': list(range(i))}, sequence=i*5)

    # Only last 3 should remain
    import glob
    research_files = list(Path(td).glob('test-run/research_*.json'))
    assert len(research_files) == 3, f'Expected 3, got {len(research_files)}'

    # Load latest research
    state = mgr.load_latest_checkpoint('research')
    assert len(state['completed']) == 7

    # Test checksum validation (corrupt a file)
    latest = sorted(Path(td).glob('test-run/research_*.json'))[-1]
    latest.write_text('{\"corrupted\": true}')
    # Should fall back to previous checkpoint
    state = mgr.load_latest_checkpoint('research')
    assert state is not None
    print('ALL CHECKPOINT TESTS PASSED')
"`
  </verify>
  <done>CheckpointManager class exists with save_checkpoint(), load_latest_checkpoint(), has_checkpoint(), _get_checkpoint_candidates(), and _cleanup_old_checkpoints(). Checkpoints use atomic writes with SHA-256 validation. Last 3 research checkpoints retained. Rollback to previous checkpoint on corruption.</done>
</task>

<task type="auto">
  <name>Task 2: Integrate checkpoints into pipeline and add --resume flag</name>
  <files>src/app.py</files>
  <action>
Modify src/app.py to support checkpoint-based resume:

1. **Add --resume argument** to the argparse section (after --compare):
   ```python
   parser.add_argument(
       "--resume",
       type=str,
       metavar="RUN_ID",
       default=None,
       help="Resume an interrupted run from its last checkpoint (provide the run_id)"
   )
   ```

2. **Update run_research_pipeline() signature** to accept optional resume_from parameter:
   ```python
   def run_research_pipeline(
       user_input: UserInput,
       progress_callback: Optional[Callable[[str], None]] = None,
       resume_from: Optional[str] = None
   ) -> RunResult:
   ```

3. **Add checkpoint logic inside run_research_pipeline()** at the start of the try block (after creating run_result):
   ```python
   from research.checkpoints import CheckpointManager

   checkpoint_mgr = CheckpointManager(user_input.run_id, settings.CHECKPOINT_DIR)
   candidates = None
   completed_suburbs = set()
   metrics_list = []

   # Resume from checkpoint if requested
   if resume_from:
       _progress(f"Attempting to resume run: {resume_from}")

       # Try loading discovery checkpoint
       discovery_state = checkpoint_mgr.load_latest_checkpoint("discovery")
       if discovery_state:
           from research.suburb_discovery import SuburbCandidate
           candidates = [SuburbCandidate(d) for d in discovery_state["candidates"]]
           _progress(f"Resumed discovery: {len(candidates)} candidates from checkpoint")

       # Try loading research checkpoint
       research_state = checkpoint_mgr.load_latest_checkpoint("research")
       if research_state:
           completed_suburbs = set(research_state.get("completed_suburbs", []))
           # Rebuild metrics_list from checkpoint
           from models.suburb_metrics import SuburbMetrics
           metrics_list = [SuburbMetrics.from_dict(d) for d in research_state.get("metrics_list", [])]
           _progress(f"Resumed research: {len(completed_suburbs)} suburbs already completed")
   ```

4. **Modify Step 1 (Discovery)** to checkpoint after completion and skip if resumed:
   - Wrap discovery in `if candidates is None:` check
   - After `parallel_discover_suburbs()` succeeds, save discovery checkpoint:
     ```python
     checkpoint_mgr.save_checkpoint("discovery", {
         "candidates": [c.to_dict() for c in candidates]
     })
     ```

5. **Modify Step 2 (Research)** to checkpoint every 5 suburbs and skip completed:
   - Before the research call, filter out completed suburbs:
     ```python
     if completed_suburbs:
         original_count = len(candidates)
         candidates = [c for c in candidates if f"{c.name}_{c.state}" not in completed_suburbs]
         _progress(f"Skipping {original_count - len(candidates)} already-completed suburbs")
     ```
   - After parallel_research_suburbs() returns, save a research checkpoint with all completed work:
     ```python
     # Add newly researched suburbs to completed set
     for m in new_metrics:
         completed_suburbs.add(f"{m.identification.name}_{m.identification.state}")
     metrics_list.extend(new_metrics)

     checkpoint_mgr.save_checkpoint("research", {
         "completed_suburbs": list(completed_suburbs),
         "metrics_list": [m.to_dict() for m in metrics_list]
     }, sequence=len(completed_suburbs))
     ```

   NOTE: The current parallel_research_suburbs() processes all at once. For checkpointing every 5 suburbs, you need to batch the candidates into groups of 5 and call parallel_research_suburbs() for each batch, saving a checkpoint after each batch. Modify the research step to:
   ```python
   research_candidates = candidates[:research_count]
   batch_size = 5
   for batch_start in range(0, len(research_candidates), batch_size):
       batch = research_candidates[batch_start:batch_start + batch_size]
       batch_metrics = parallel_research_suburbs(
           batch, user_input.dwelling_type, user_input.max_median_price,
           max_suburbs=len(batch), provider=user_input.provider,
           progress_callback=progress_callback
       )
       for m in batch_metrics:
           completed_suburbs.add(f"{m.identification.name}_{m.identification.state}")
           metrics_list.append(m)

       checkpoint_mgr.save_checkpoint("research", {
           "completed_suburbs": list(completed_suburbs),
           "metrics_list": [m.to_dict() for m in metrics_list]
       }, sequence=len(completed_suburbs))
       _progress(f"Checkpoint saved: {len(completed_suburbs)} suburbs completed")
   ```

6. **Add to_dict() and from_dict() methods** if they don't exist on SuburbCandidate (in suburb_discovery.py) and SuburbMetrics (in models/suburb_metrics.py). Check if these already exist. SuburbCandidate already takes a dict in __init__, so to_dict() just needs to return its attributes as a dict. For SuburbMetrics, check if dataclasses.asdict works or if a custom method is needed.

   For SuburbCandidate in suburb_discovery.py, add:
   ```python
   def to_dict(self) -> dict:
       return {
           "name": self.name, "state": self.state, "lga": self.lga,
           "region": self.region, "median_price": self.median_price,
           "growth_signals": self.growth_signals,
           "major_events_relevance": self.major_events_relevance,
           "data_quality": self.data_quality
       }
   ```

7. **Handle --resume in main()** after argument parsing:
   ```python
   if args.resume:
       # Resume mode: use the provided run_id
       user_input = UserInput(
           max_median_price=args.max_price,
           dwelling_type=args.dwelling_type,
           regions=args.regions,
           num_suburbs=args.num_suburbs,
           provider=args.provider,
           run_id=args.resume,
           interface_mode="cli"
       )
       run_result = run_research_pipeline(user_input, resume_from=args.resume)
   ```

Important: The web server in src/ui/web/server.py calls run_research_pipeline() -- the new resume_from parameter has a default of None so it won't break existing calls.
  </action>
  <verify>
Run these checks:
1. `cd /Users/robertli/Desktop/local-projects/agentic-re-researcher && python -c "from src.app import run_research_pipeline; import inspect; sig = inspect.signature(run_research_pipeline); assert 'resume_from' in sig.parameters; print('resume_from param OK')"`
2. `python -c "from src.app import main; print('main import OK')"`
3. `python -m src.app --help` should show --resume in the output
4. `python -c "from src.research.suburb_discovery import SuburbCandidate; c = SuburbCandidate({'name': 'Test', 'state': 'QLD'}); d = c.to_dict(); assert d['name'] == 'Test'; print('to_dict OK')"`
  </verify>
  <done>
--resume flag exists in CLI argument parser. run_research_pipeline() accepts resume_from parameter. Discovery checkpoint saved after parallel_discover_suburbs(). Research checkpointed every 5 suburbs in batches. Resume loads latest valid checkpoint, skips completed suburbs, continues from last checkpoint. SuburbCandidate has to_dict(). Web server calls are not broken (resume_from defaults to None).
  </done>
</task>

</tasks>

<verification>
1. CheckpointManager saves/loads checkpoints with SHA-256 validation
2. Corrupted checkpoint falls back to previous valid checkpoint
3. Only last 3 research checkpoints retained
4. --resume flag loads checkpoints and skips completed suburbs
5. Discovery checkpoint saved after discovery phase
6. Research checkpoint saved every 5 suburbs
7. Atomic writes used for all checkpoint files (via atomic_write_json from cache.py)
8. Web server pipeline call not broken by new parameter
</verification>

<success_criteria>
- CheckpointManager class in src/research/checkpoints.py with save/load/rollback
- --resume RUN_ID flag in CLI argument parser
- Discovery checkpoint created after parallel_discover_suburbs()
- Research checkpoints created every 5 suburbs during research
- Resume skips already-completed suburbs
- Corrupted checkpoint triggers fallback to previous valid checkpoint
- Last 3 research checkpoints retained, older ones cleaned up
- All checkpoint files use atomic_write_json() with SHA-256 checksums
</success_criteria>

<output>
After completion, create `.planning/phases/03-cache-hardening-crash-recovery/03-02-SUMMARY.md`
</output>
