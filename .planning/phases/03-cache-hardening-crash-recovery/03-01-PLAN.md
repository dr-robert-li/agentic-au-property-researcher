---
phase: 03-cache-hardening-crash-recovery
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/research/cache.py
  - src/security/exceptions.py
  - src/config/settings.py
autonomous: true

must_haves:
  truths:
    - "Killing the process mid-write (kill -9) never leaves a corrupted cache file"
    - "Running the app after deleting the cache index recovers from backup and reports what was restored"
    - "Orphaned cache files (files without index entries) are cleaned up on startup"
    - "Cache directory stays within the configured size limit by automatically evicting least-recently-used entries"
  artifacts:
    - path: "src/research/cache.py"
      provides: "Atomic writes, backup/restore, orphan cleanup, LRU eviction"
      contains: "atomic_write"
    - path: "src/security/exceptions.py"
      provides: "CacheError exception type"
      contains: "class CacheError"
    - path: "src/config/settings.py"
      provides: "CACHE_MAX_SIZE_MB and CHECKPOINT_DIR settings"
      contains: "CACHE_MAX_SIZE_MB"
  key_links:
    - from: "src/research/cache.py"
      to: "src/security/exceptions.py"
      via: "CacheError import"
      pattern: "from security.exceptions import.*CacheError"
    - from: "src/research/cache.py"
      to: "src/config/settings.py"
      via: "CACHE_MAX_SIZE_MB config"
      pattern: "settings\\.CACHE_MAX_SIZE_MB"
---

<objective>
Harden the file-based cache in src/research/cache.py against corruption, data loss, and unbounded growth.

Purpose: Cache files must survive process crashes (kill -9) without corruption. The cache index must have backup/restore capability. Orphaned files must be cleaned up on startup. Cache size must be bounded with LRU eviction.

Output: Enhanced cache.py with atomic writes, backup/restore, orphan cleanup, and LRU eviction. New CacheError exception type. New cache settings in settings.py.
</objective>

<execution_context>
@.planning/phases/03-cache-hardening-crash-recovery/03-RESEARCH.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@src/research/cache.py
@src/security/exceptions.py
@src/config/settings.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add CacheError exception and cache settings</name>
  <files>src/security/exceptions.py, src/config/settings.py</files>
  <action>
1. In src/security/exceptions.py, add a CacheError class under the Research-Specific Errors section:
   ```python
   class CacheError(ApplicationError):
       """Cache operation failed (corruption, I/O error, eviction failure)."""
       def __init__(self, message: str, operation: Optional[str] = None, is_transient: bool = True):
           super().__init__(message=message, error_code="CACHE_ERROR", is_transient=is_transient)
           self.operation = operation  # "read", "write", "evict", "restore"
   ```

2. In src/config/settings.py, add after the existing cache config lines (after CACHE_RESEARCH_TTL):
   ```python
   CACHE_MAX_SIZE_MB = int(os.getenv("CACHE_MAX_SIZE_MB", "500"))  # 500 MB default
   CHECKPOINT_DIR = BASE_DIR / "checkpoints"
   CHECKPOINT_DIR.mkdir(exist_ok=True)
   ```
  </action>
  <verify>
Run: `cd /Users/robertli/Desktop/local-projects/agentic-re-researcher && python -c "from src.security.exceptions import CacheError; print('CacheError OK'); from src.config import settings; print(f'CACHE_MAX_SIZE_MB={settings.CACHE_MAX_SIZE_MB}'); print(f'CHECKPOINT_DIR={settings.CHECKPOINT_DIR}')"` -- should print CacheError OK and the config values.
  </verify>
  <done>CacheError exception exists in exceptions.py. CACHE_MAX_SIZE_MB and CHECKPOINT_DIR settings exist in settings.py with env var overrides.</done>
</task>

<task type="auto">
  <name>Task 2: Implement atomic writes, backup/restore, orphan cleanup, and LRU eviction in cache.py</name>
  <files>src/research/cache.py</files>
  <action>
Refactor src/research/cache.py with these changes (preserve ALL existing public API methods -- get, put, invalidate, clear, stats, bucket_price, get_cache, reset_cache_instance):

1. **Add atomic_write_json() module-level function** (before ResearchCache class):
   - Use `tempfile.NamedTemporaryFile(mode='w', dir=parent_dir, delete=False, prefix='.tmp_', suffix='.tmp')`
   - Write JSON content, flush(), os.fsync(tmp.fileno()), close tmp, then os.replace(tmp_path, target_path)
   - On POSIX (os.name != 'nt'), fsync the parent directory after replace
   - On any exception, clean up tmp file and re-raise
   - Import tempfile at top of file
   - Raise CacheError on failure (wrap OSError)

2. **Enhance CacheEntry dataclass** -- add two new fields with defaults (backward compatible with existing serialized data):
   - `size_bytes: int = 0`
   - `last_accessed: float = 0.0`

3. **Enhance CacheConfig dataclass** -- add:
   - `max_size_bytes: int = 500 * 1024 * 1024` (500 MB default)

4. **Replace _save_index()** to use atomic writes + backup:
   - Serialize index to JSON string
   - Call atomic_write_json() for the main index file
   - After successful write, copy main index to `cache_index.json.backup` using shutil.copy2()
   - Import shutil at top

5. **Replace _load_index()** with backup/restore logic:
   - Try loading main index file; if JSON parse fails, log warning "Cache index corrupted: {e}"
   - Try loading backup file (cache_index.json.backup); if success, log "Restoring from backup index..." and copy backup over main using shutil.copy2(), return parsed data
   - If both fail, log "Starting with empty cache index" and return {}
   - When restoring from backup, log how many entries were restored

6. **Add _cleanup_orphans() method** called at end of __init__():
   - Load index, get set of indexed filenames
   - Glob cache_dir for 'discovery_*.json' and 'research_*.json'
   - Protected files: INDEX_FILE, INDEX_FILE + '.backup', and any '.tmp_*' files
   - Delete any cache files not in indexed_files and not protected
   - Log each deleted orphan and total count

7. **Add _enforce_size_limit(new_entry_size: int) method**:
   - Read CACHE_MAX_SIZE_MB from settings (imported), convert to bytes
   - If max_size <= 0, return (no limit)
   - Load index, sum size_bytes for total
   - If total + new_entry_size <= limit, return
   - Sort entries by last_accessed ascending (LRU first)
   - Delete files and remove from index until under limit
   - Save updated index
   - Log each eviction with filename and size

8. **Update put() method**:
   - Replace `with open(data_path, "w")` with `atomic_write_json(data_path, data)`
   - After writing, get file size: `data_path.stat().st_size`
   - Call `self._enforce_size_limit(file_size)` BEFORE adding to index
   - Set `size_bytes=file_size` and `last_accessed=time.time()` on CacheEntry

9. **Update get() method**:
   - After successful read, update `entry.last_accessed = time.time()` and save index

10. **Update stats() method**:
    - Add `max_size_bytes` to returned dict (from settings)
    - Use entry.size_bytes instead of stat() calls for total_size (faster, consistent)

Keep the existing RLock synchronization. All index operations already happen under self._lock.

Do NOT change the public API signatures of get(), put(), invalidate(), clear(), get_cache(), reset_cache_instance(). The CacheEntry additions have defaults so existing serialized indexes will still deserialize.
  </action>
  <verify>
Run these checks:
1. `cd /Users/robertli/Desktop/local-projects/agentic-re-researcher && python -c "from src.research.cache import ResearchCache, CacheConfig, atomic_write_json; from pathlib import Path; print('imports OK')"`
2. `python -c "
from src.research.cache import ResearchCache, CacheConfig, atomic_write_json
from pathlib import Path
import tempfile, json

# Test atomic write
with tempfile.TemporaryDirectory() as td:
    p = Path(td) / 'test.json'
    atomic_write_json(p, {'hello': 'world'})
    assert json.loads(p.read_text()) == {'hello': 'world'}
    print('atomic_write_json OK')

    # Test cache with backup/restore
    config = CacheConfig(cache_dir=Path(td) / 'cache', max_size_bytes=1024*1024)
    cache = ResearchCache(config)
    cache.put('discovery', {'data': 'test'}, region='test')
    result = cache.get('discovery', region='test')
    assert result == {'data': 'test'}
    print('put/get OK')

    # Verify backup exists
    backup = config.cache_dir / 'cache_index.json.backup'
    assert backup.exists()
    print('backup exists OK')

    # Verify stats includes max_size
    stats = cache.stats()
    assert 'max_size_bytes' in stats
    print('stats OK')

    print('ALL TESTS PASSED')
"`
  </verify>
  <done>
Cache writes use atomic temp-file + fsync + rename pattern. Cache index has backup that is created on every save. Index load falls back to backup on corruption. Orphan files are cleaned on startup. LRU eviction enforces size limit. CacheEntry tracks size_bytes and last_accessed. All existing public API preserved.
  </done>
</task>

</tasks>

<verification>
1. Atomic writes: `atomic_write_json()` uses tempfile + os.replace() pattern from research
2. Backup/restore: `_save_index()` creates .backup; `_load_index()` falls back to it
3. Orphan cleanup: `_cleanup_orphans()` runs in `__init__()`, deletes unindexed files
4. LRU eviction: `_enforce_size_limit()` called in `put()` before adding entry
5. All existing tests/imports still work (public API unchanged)
</verification>

<success_criteria>
- atomic_write_json() function exists and uses tempfile + os.replace() + fsync
- CacheEntry has size_bytes and last_accessed fields
- _save_index() creates backup file after each save
- _load_index() recovers from backup when main index is corrupted
- _cleanup_orphans() removes files not in index on startup
- _enforce_size_limit() evicts LRU entries when cache exceeds CACHE_MAX_SIZE_MB
- CacheError exception type exists in exceptions.py
- CACHE_MAX_SIZE_MB and CHECKPOINT_DIR exist in settings.py
</success_criteria>

<output>
After completion, create `.planning/phases/03-cache-hardening-crash-recovery/03-01-SUMMARY.md`
</output>
